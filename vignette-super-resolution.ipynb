{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fbf7857",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360a0a1",
   "metadata": {},
   "source": [
    "Our objective for the final project is to reconstruct a high-resolution (HR) image from its corresponding low-resolution (LR) counterpart. To accomplish this, we have selected the ESPCNN model, known for its effectiveness in image restoration tasks. The training process involves obtaining and preprocessing a suitable dataset, followed by training the ESPCNN model using the prepared data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49160547",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991ad4c",
   "metadata": {},
   "source": [
    "## Data and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f7c67",
   "metadata": {},
   "source": [
    "In order to launch our project effectively, we meticulously chose a substantial image dataset to thoroughly evaluate our model's performance by comparing the before and after images upon input. Our image dataset consists of around 4,000 low-resolution images of wild animals from Kaggle(https://www.kaggle.com/datasets/dimensi0n/afhq-512?select=wild), each with dimensions of 3x512x512 (3 RGB color channel represents colored images instead of grey-scaled images, with 512x512 pixel length and width). We then pre-processed the images by resizing them into 3x128x128 images (found in main.py). Lastly, we transform each of the images into tensor objects for easy input into our model in order to train our model effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa227ca",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43d29863",
   "metadata": {},
   "source": [
    "![alt text](https://github.com/PSTAT197-F23/vignette-super-resolution/blob/main/image/Model%20Explanation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af700ca7",
   "metadata": {},
   "source": [
    "The model we use is called an efficient sub-pixel convolutional neural network(ESPCN). As we can see on the diagram, we first feed the model with a low resolution image, and we apply CNN layer to get feature maps. With those feature maps we can get number of channels that is greater than the original 3. With these channels we applied the pixel shuffle method which is the most important step for the sub-pixel convolution network. The concept of sub-pixel is that we believe that we have tiny pixels between the two physical pixels in the microscopic world. The reason for this sub-pixel convolution network is to reveal this sub-pixel relationship. As we can see on the diagram, each pixel on the feature maps represents each sub-pixel on the high resolution image. Our model contains three convolution layers which increase the channel size to 48. With these channels we can use the SPC layer in order to get the high resolution picture. In addition, the activation function we used was ReLU, because it can turn the linear relationships into non-linear ones, and it is not computationally heavy which means we can train more epochs with less time and get better results. The loss function we used was MSE. The original 512 x 512 image would be the label and the down-sampled 128 x 128 picture was our input. The loss function is shown below:<br> \n",
    "$\\ell(W_{1:L, b_{1:L}}) = \\frac{1}{r^2HW}\\sum\\limits_{x=1}^{rH}\\sum\\limits_{x=1}^{rW}\\left( I^{HR}_{x,y} - f^L_{x,y}(I^{LR}) \\right)^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d1729",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447e4c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42d09a1b",
   "metadata": {},
   "source": [
    "# Code Appendix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21aff7",
   "metadata": {},
   "source": [
    "### Run the scripts to reproduce the result. Do not run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b9333",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath)\n",
    "    return img\n",
    "\n",
    "class DatasetFromFolder(Dataset):\n",
    "    def __init__(self, image_dir, scale_factor):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n",
    "        self.tensor = transforms.ToTensor()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        target = input.copy()\n",
    "    \n",
    "        input = self.tensor(input)\n",
    "        target = self.tensor(target)\n",
    "        \n",
    "        height, width = transforms.functional.get_image_size(input)\n",
    "        resize = transforms.Resize((int(height/self.scale_factor), int(width/self.scale_factor)), \n",
    "                                  transforms.InterpolationMode.BICUBIC, \n",
    "                                  antialias=True\n",
    "                                 )\n",
    "        input = resize(input)\n",
    "        del(resize)\n",
    "        \n",
    "        return input, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4f465",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5082fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(64, 3 * scale_factor ** 2, kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.clamp(x, 0.0, 1.0)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07c1bf",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d88c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# import dataset.py and model.py\n",
    "from dataset import *\n",
    "from model import *\n",
    "\n",
    "\n",
    "# main helper functions\n",
    "def swap(img):\n",
    "    img = img.swapaxes(0, 1)\n",
    "    img = img.swapaxes(1, 2)\n",
    "    return img\n",
    "\n",
    "def train(epoch, model):\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_history = []\n",
    "    epoch_test_loss_history = []\n",
    "    \n",
    "    for iteration, batch in enumerate(train_dataloader, 1):\n",
    "        img, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(img), target)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 5 == 0:\n",
    "            tbatch = next(iter(test_dataloader))\n",
    "            timg, ttarget = tbatch[0].to(device), tbatch[1].to(device)\n",
    "            tloss = criterion(model(timg), ttarget)\n",
    "            \n",
    "            epoch_loss_history.append(loss.item())\n",
    "            epoch_test_loss_history.append(tloss.item())\n",
    "            \n",
    "            print(\"===> Epoch[{}]({}/{}): Loss: {:.6f}, Test Loss: {:.6f}\".format(\n",
    "                epoch+1, iteration, len(train_dataloader), loss.item(), tloss.item()))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.6f}\".format(epoch+1, epoch_loss / len(train_dataloader)))\n",
    "    \n",
    "    return epoch_loss_history, epoch_test_loss_history\n",
    "\n",
    "\n",
    "# set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    \n",
    "# set hyperparameter\n",
    "scale_factor    = 4\n",
    "batch_size      = 32\n",
    "epoch           = 5\n",
    "learning_rate   = 0.0003\n",
    "criterion       = nn.MSELoss()\n",
    "\n",
    "\n",
    "# load data\n",
    "train_data = DatasetFromFolder(\"../data/train/wild\", scale_factor=scale_factor)\n",
    "test_data = DatasetFromFolder(\"../data/train/wild\", scale_factor=scale_factor)\n",
    "ref_data = DatasetFromFolder(\"../data/loss\", scale_factor=scale_factor)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "ref_dataloader = DataLoader(ref_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Model(scale_factor=scale_factor).to(device)\n",
    "\n",
    "\n",
    "# train\n",
    "figure, ax = plt.subplots(3, epoch)\n",
    "figure.set_size_inches(20, 15)\n",
    "\n",
    "loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(epoch):\n",
    "    epoch_loss_history, epoch_test_loss_history = train(i, model)\n",
    "    loss_history = loss_history + epoch_loss_history\n",
    "    test_loss_history = test_loss_history + epoch_test_loss_history\n",
    "    del(epoch_loss_history)\n",
    "    del(epoch_test_loss_history)\n",
    "    \n",
    "    ref = next(iter(ref_dataloader))[0]\n",
    "    ref_tgt = next(iter(ref_dataloader))[1]\n",
    "    ref_fit = model(ref.to(device)).cpu()\n",
    "    \n",
    "    ref = swap(ref.squeeze())\n",
    "    ref_tgt = swap(ref_tgt.squeeze())\n",
    "    ref_fit = swap(ref_fit.detach().numpy().squeeze())\n",
    "\n",
    "    ax[0, i].imshow(ref)\n",
    "    ax[1, i].imshow(ref_fit)\n",
    "    ax[2, i].imshow(ref_tgt)\n",
    "\n",
    "figure.savefig('../image/reference.jpg')\n",
    "\n",
    "\n",
    "# plot loss\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(loss_history)\n",
    "plt.plot(test_loss_history)\n",
    "plt.savefig('../image/loss.jpg')\n",
    "\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), '../model/model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352df0db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313657ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
