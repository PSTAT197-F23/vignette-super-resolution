{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd92025",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e6d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52532fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3384c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath)\n",
    "    return img\n",
    "\n",
    "class DatasetFromFolder(Dataset):\n",
    "    def __init__(self, image_dir, scale_factor):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n",
    "        self.tensor = transforms.ToTensor()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        target = input.copy()\n",
    "    \n",
    "        input = self.tensor(input)\n",
    "        target = self.tensor(target)\n",
    "        \n",
    "        height, width = transforms.functional.get_image_size(input)\n",
    "        resize = transforms.Resize((int(height/self.scale_factor), int(width/self.scale_factor)), \n",
    "                                  transforms.InterpolationMode.BICUBIC, \n",
    "                                  antialias=True\n",
    "                                 )\n",
    "        input = resize(input)\n",
    "        del(resize)\n",
    "        \n",
    "        return input, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf06b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(64, 3 * scale_factor ** 2, kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.clamp(x, 0.0, 1.0)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3a43ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# import dataset.py and model.py\n",
    "from dataset import *\n",
    "from model import *\n",
    "\n",
    "\n",
    "# main helper functions\n",
    "def swap(img):\n",
    "    img = img.swapaxes(0, 1)\n",
    "    img = img.swapaxes(1, 2)\n",
    "    return img\n",
    "\n",
    "def train(epoch, model):\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_history = []\n",
    "    epoch_test_loss_history = []\n",
    "    \n",
    "    for iteration, batch in enumerate(train_dataloader, 1):\n",
    "        img, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(img), target)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 5 == 0:\n",
    "            tbatch = next(iter(test_dataloader))\n",
    "            timg, ttarget = tbatch[0].to(device), tbatch[1].to(device)\n",
    "            tloss = criterion(model(timg), ttarget)\n",
    "            \n",
    "            epoch_loss_history.append(loss.item())\n",
    "            epoch_test_loss_history.append(tloss.item())\n",
    "            \n",
    "            print(\"===> Epoch[{}]({}/{}): Loss: {:.6f}, Test Loss: {:.6f}\".format(\n",
    "                epoch+1, iteration, len(train_dataloader), loss.item(), tloss.item()))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.6f}\".format(epoch+1, epoch_loss / len(train_dataloader)))\n",
    "    \n",
    "    return epoch_loss_history, epoch_test_loss_history\n",
    "\n",
    "\n",
    "# set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    \n",
    "# set hyperparameter\n",
    "scale_factor    = 4\n",
    "batch_size      = 32\n",
    "epoch           = 5\n",
    "learning_rate   = 0.0003\n",
    "criterion       = nn.MSELoss()\n",
    "\n",
    "\n",
    "# load data\n",
    "train_data = DatasetFromFolder(\"../data/train/wild\", scale_factor=scale_factor)\n",
    "test_data = DatasetFromFolder(\"../data/train/wild\", scale_factor=scale_factor)\n",
    "ref_data = DatasetFromFolder(\"../data/loss\", scale_factor=scale_factor)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "ref_dataloader = DataLoader(ref_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Model(scale_factor=scale_factor).to(device)\n",
    "\n",
    "\n",
    "# train\n",
    "figure, ax = plt.subplots(3, epoch)\n",
    "figure.set_size_inches(20, 15)\n",
    "\n",
    "loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(epoch):\n",
    "    epoch_loss_history, epoch_test_loss_history = train(i, model)\n",
    "    loss_history = loss_history + epoch_loss_history\n",
    "    test_loss_history = test_loss_history + epoch_test_loss_history\n",
    "    del(epoch_loss_history)\n",
    "    del(epoch_test_loss_history)\n",
    "    \n",
    "    ref = next(iter(ref_dataloader))[0]\n",
    "    ref_tgt = next(iter(ref_dataloader))[1]\n",
    "    ref_fit = model(ref.to(device)).cpu()\n",
    "    \n",
    "    ref = swap(ref.squeeze())\n",
    "    ref_tgt = swap(ref_tgt.squeeze())\n",
    "    ref_fit = swap(ref_fit.detach().numpy().squeeze())\n",
    "\n",
    "    ax[0, i].imshow(ref)\n",
    "    ax[1, i].imshow(ref_fit)\n",
    "    ax[2, i].imshow(ref_tgt)\n",
    "\n",
    "figure.show()\n",
    "\n",
    "\n",
    "# plot loss\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(loss_history)\n",
    "plt.plot(test_loss_history)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), '../model/model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f9dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6299737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbba311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f953f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e09b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
